{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767f6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\RAG\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a51d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\rag\\venv\\lib\\site-packages (0.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\rag\\venv\\lib\\site-packages (from rank_bm25) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9da885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────\n",
    "# SETUP: Create our sample company data\n",
    "# ──────────────────────────────────────────────────────────────────\n",
    "\n",
    "chunks = [\n",
    "    \"Microsoft acquired GitHub for 7.5 billion dollars in 2018.\",\n",
    "    \"Tesla Cybertruck production ramp begins in 2024.\",\n",
    "    \"Google is a large technology company with global operations.\",\n",
    "    \"Tesla reported strong quarterly results. Tesla continues to lead in electric vehicles. Tesla announced new manufacturing facilities.\",\n",
    "    \"SpaceX develops Starship rockets for Mars missions.\",\n",
    "    \"The tech giant acquired the code repository platform for software development.\",\n",
    "    \"NVIDIA designs Starship architecture for their new GPUs.\",\n",
    "    \"Tesla Tesla Tesla financial quarterly results improved significantly.\",\n",
    "    \"Cybertruck reservations exceeded company expectations.\",\n",
    "    \"Microsoft is a large technology company with global operations.\", \n",
    "    \"Apple announced new iPhone features for developers.\",\n",
    "    \"The apple orchard harvest was excellent this year.\",\n",
    "    \"Python programming language is widely used in AI.\",\n",
    "    \"The python snake can grow up to 20 feet long.\",\n",
    "    \"Java coffee beans are imported from Indonesia.\", \n",
    "    \"Java programming requires understanding of object-oriented concepts.\",\n",
    "    \"Orange juice sales increased during winter months.\",\n",
    "    \"Orange County reported new housing developments.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36f32304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data:\n",
      "1. Microsoft acquired GitHub for 7.5 billion dollars in 2018.\n",
      "2. Tesla Cybertruck production ramp begins in 2024.\n",
      "3. Google is a large technology company with global operations.\n",
      "4. Tesla reported strong quarterly results. Tesla continues to lead in electric vehicles. Tesla announced new manufacturing facilities.\n",
      "5. SpaceX develops Starship rockets for Mars missions.\n",
      "6. The tech giant acquired the code repository platform for software development.\n",
      "7. NVIDIA designs Starship architecture for their new GPUs.\n",
      "8. Tesla Tesla Tesla financial quarterly results improved significantly.\n",
      "9. Cybertruck reservations exceeded company expectations.\n",
      "10. Microsoft is a large technology company with global operations.\n",
      "11. Apple announced new iPhone features for developers.\n",
      "12. The apple orchard harvest was excellent this year.\n",
      "13. Python programming language is widely used in AI.\n",
      "14. The python snake can grow up to 20 feet long.\n",
      "15. Java coffee beans are imported from Indonesia.\n",
      "16. Java programming requires understanding of object-oriented concepts.\n",
      "17. Orange juice sales increased during winter months.\n",
      "18. Orange County reported new housing developments.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Convert to Document objects for LangChain\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": f\"chunk_{i}\"}) for i, chunk in enumerate(chunks)]\n",
    "\n",
    "print(\"Sample Data:\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"{i}. {chunk}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad37b71",
   "metadata": {},
   "source": [
    "1. Vector Retriever (Semantic Search/Dense Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df59881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Vector Retriever...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up Vector Retriever...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2055815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 'space exploration company'\n",
      "Found: SpaceX develops Starship rockets for Mars missions.\n",
      "Found: Google is a large technology company with global operations.\n"
     ]
    }
   ],
   "source": [
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Test semantic search\n",
    "test_query = \"space exploration company\" #works in vector search but wouldn't work with keyword search\n",
    "\n",
    "print(f\"Testing: '{test_query}'\")\n",
    "test_docs = vector_retriever.invoke(test_query)\n",
    "for doc in test_docs:\n",
    "    print(f\"Found: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991fd35c",
   "metadata": {},
   "source": [
    "2. BM25 Retriever (Keyword Search/Sparse Retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80995af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up BM25 Retriever...\n"
     ]
    }
   ],
   "source": [
    "# 2. BM25 Retriever (Keyword Search)\n",
    "print(\"Setting up BM25 Retriever...\")\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5973539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 'Tesla'\n",
      "Found: Tesla Tesla Tesla financial quarterly results improved significantly.\n",
      "Found: Tesla reported strong quarterly results. Tesla continues to lead in electric vehicles. Tesla announced new manufacturing facilities.\n",
      "Found: Tesla Cybertruck production ramp begins in 2024.\n"
     ]
    }
   ],
   "source": [
    "# Test exact keyword matching\n",
    "# test_query = \"space exploration company\"\n",
    "# test_query = \"Cybertruck\"\n",
    "test_query = \"Tesla\"\n",
    "\n",
    "print(f\"Testing: '{test_query}'\")\n",
    "test_docs = bm25_retriever.invoke(test_query)\n",
    "for doc in test_docs:\n",
    "    print(f\"Found: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4d6be",
   "metadata": {},
   "source": [
    "3. Hybrid Retriever (Combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928e8704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Hybrid Retriever...\n",
      "Setup complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  3. Hybrid Retriever (Combination)\n",
    "# 3. Hybrid Retriever (Combination) – LangChain 1.x compatible\n",
    "\n",
    "print(\"Setting up Hybrid Retriever...\")\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def hybrid_search(query: str, k: int = 4):\n",
    "    vector_docs = vector_retriever.invoke(query)\n",
    "    bm25_docs = bm25_retriever.invoke(query)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    # Vector retriever weight = 0.7\n",
    "    for rank, doc in enumerate(vector_docs):\n",
    "        scores[doc.page_content] = scores.get(doc.page_content, 0) + 0.7 * (1 / (rank + 1))\n",
    "\n",
    "    # BM25 retriever weight = 0.3\n",
    "    for rank, doc in enumerate(bm25_docs):\n",
    "        scores[doc.page_content] = scores.get(doc.page_content, 0) + 0.3 * (1 / (rank + 1))\n",
    "\n",
    "    ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in ranked_docs[:k]]\n",
    "\n",
    "hybrid_retriever = RunnableLambda(hybrid_search)\n",
    "\n",
    "print(\"Setup complete!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17040f95",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m retrieved_chunks \u001b[38;5;241m=\u001b[39m hybrid_retriever\u001b[38;5;241m.\u001b[39minvoke(test_query)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(retrieved_chunks, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery 1 shows how hybrid finds exact financial info using both semantic understanding and keyword matching\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# Query 1: Mixed semantic and exact terms\n",
    "\n",
    "# Vector search understands \"purchase cost\" semantically\n",
    "# BM25 search finds exact \"7.5 billion\" \n",
    "# Hybrid should combine both strengths for best result\n",
    "test_query = \"purchase cost 7.5 billion\"\n",
    "\n",
    "retrieved_chunks = hybrid_retriever.invoke(test_query)\n",
    "for i, doc in enumerate(retrieved_chunks, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "print()\n",
    "\n",
    "print(\"Query 1 shows how hybrid finds exact financial info using both semantic understanding and keyword matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Semantic concept + specific product name  \n",
    "\n",
    "# Vector search understands \"electric vehicle manufacturing\"\n",
    "# BM25 search finds exact \"Cybertruck\"\n",
    "# Hybrid gets the best of both worlds\n",
    "\n",
    "test_query = \"electric vehicle manufacturing Cybertruck\"\n",
    "\n",
    "retrieved_chunks = hybrid_retriever.invoke(test_query)\n",
    "\n",
    "for i, doc in enumerate(retrieved_chunks, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "print()\n",
    "\n",
    "print(\"Query 2 demonstrates combining product-specific terms with broader concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebf4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Where neither alone would be perfect\n",
    "\n",
    "# \"Company performance\" is semantic, \"Tesla\" is exact keyword\n",
    "# Hybrid should find the most relevant Tesla performance info\n",
    "\n",
    "test_query = \"company performance Tesla\"\n",
    "\n",
    "retrieved_chunks = hybrid_retriever.invoke(test_query)\n",
    "for i, doc in enumerate(retrieved_chunks, 1):\n",
    "    print(f\"{i}. {doc.page_content}\")\n",
    "print()\n",
    "\n",
    "print(\"Query 3 shows how hybrid handles mixed semantic/keyword queries better than either approach alone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the query and the relevant document contents\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "combined_input = f\"\"\"Based on the following documents, please answer this question: {test_query}\n",
    "\n",
    "Documents:\n",
    "{chr(10).join([f\"- {doc.page_content}\" for doc in retrieved_chunks])}\n",
    "\n",
    "Please provide a clear, helpful answer using only the information from these documents. If you can't find the answer in the documents, say \"I don't have enough information to answer that question based on the provided documents.\"\n",
    "\"\"\"\n",
    "\n",
    "# Create a ChatOllama model\n",
    "model = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Define the messages for the model\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=combined_input),\n",
    "]\n",
    "\n",
    "# Invoke the model with the combined input\n",
    "result = model.invoke(messages)\n",
    "\n",
    "# Display the full result and content only\n",
    "print(\"\\n--- Generated Response ---\")\n",
    "# print(\"Full result:\")\n",
    "# print(result)\n",
    "print(\"Content only:\")\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
